
# ğŸ§  ChromaDB + Sentence-Transformers: Local Semantic Search Tutorial

> âœ… **No API keys â€¢ No cloud â€¢ 100% offline â€¢ Beginner-friendly â€¢ ChromaDB 1.0+ Compliant**

A self-contained, educational Python script that demonstrates how to build a persistent local vector store using **ChromaDB** and **Hugging Faceâ€™s BGE sentence-transformer embeddings** â€” perfect for learning, prototyping, or lightweight production use.

Built to handle all breaking changes in ChromaDB 1.0+, including:
- Removal of `client.persist()`
- Mandatory `input` parameter in embedding functions
- Requirement for `.name()` method
- Bypassing broken `HuggingFaceEmbeddingFunction` wrapper

---

## ğŸš€ Features

- ğŸ“¦ Creates a **persistent ChromaDB collection** saved to `./chroma_store`
- ğŸ§  Uses **`BAAI/bge-small-en-v1.5`** â€” a state-of-the-art, lightweight embedding model (better than `all-MiniLM-L6-v2`)
- â• **Upserts 10 sample documents** with rich metadata (`title`, `tag`, `source`) and deterministic IDs
- ğŸ” Runs **3 semantic search queries** + **1 metadata-filtered query**
- ğŸ”„ **Reloads the collection from disk** to prove persistence works
- ğŸ§ª Includes **sanity checks** (embedding shape, query variations, top-k control)
- ğŸ§‘â€ğŸ« **Fully commented** with clear section headers and error handling
- âŒ **No OpenAI, no API keys, no credentials required**

---

## ğŸ› ï¸ Requirements

- Python 3.9+
- `pip install chromadb sentence-transformers`

> ğŸ’¡ First run will download the BGE model (~100MB). Subsequent runs are fast and offline.

---

## â–¶ï¸ Quick Start

1. Clone or download this repo.
2. Install dependencies:

```bash
pip install chromadb sentence-transformers
```

3. Run the script:

```bash
python chroma_local_search.py
```

4. Watch it:
   - Download the embedding model (once)
   - Create and populate the vector store
   - Run semantic queries
   - Reload from disk to prove persistence

---

## ğŸ“„ Sample Output

```
âœ… ChromaDB version: 1.0.21
ğŸ“¥ Loading model: BAAI/bge-small-en-v1.5 (may take a moment on first run)...
âœ… Model loaded. Embedding dimension: 384
âœ… Collection 'community_demo' ready at ./chroma_store
â• Adding documents to collection...
âœ… Upserted 10 documents.
ğŸ’¾ Collection is automatically persisted to disk (Chroma 1.0+).

============================================================
ğŸ” RUNNING EXAMPLE QUERIES
============================================================

ğŸ” Query: "How do I create lists in Python?"
   Top 3 results (lower distance = more similar):

   1. ID: doc-001 | Distance: 0.1824
      Title: Python Tips | Tag: code
      Snippet: "Python list comprehensions are a concise way to create lists..."

ğŸ” Query: "powerhouse of the cell"
   Top 3 results (lower distance = more similar):

   1. ID: doc-002 | Distance: 0.1201
      Title: Biology Fact | Tag: science
      Snippet: "The mitochondria is the powerhouse of the cell..."

============================================================
FilterWhere: Only 'code' tagged documents
============================================================

ğŸ” Query: "How to manage state in components?"
   Top 3 results (lower distance = more similar):

   1. ID: doc-003 | Distance: 0.2915
      Title: React Hooks Intro | Tag: code
      Snippet: "React hooks allow function components to have state and lifecycle features..."

============================================================
ğŸ” RELOADING STORE FROM DISK
============================================================
âœ… Reload successful! Found doc: Docker containers package apps with their...

ğŸ‰ Tutorial complete! Youâ€™re using BGE embeddings â€” stable, compliant, no Chroma bugs.
```

*(Distances may vary slightly due to model updates, but rankings should be stable.)*

---

## ğŸ§© Try This Next

- ğŸ”„ **Swap the model**: Try `"BAAI/bge-base-en-v1.5"` or `"thenlper/gte-small"` for different performance/accuracy trade-offs.
- ğŸ“– **Expand the corpus**: Add your own documents to `SAMPLE_DOCS` and `METADATAS`.
- ğŸ¯ **Filter differently**: Query with `where={"source": "tutorial"}` or combine filters: `where={"$and": [{"tag": "code"}, {"source": "guide"}]}`
- ğŸ“Š **Inspect embeddings**: Uncomment `print(f"â†’ Embedding: {embedding_func(['test'])[0][:5]}...")` to see raw vectors.
- ğŸ—‘ï¸ **Reset the store**: Delete the `./chroma_store` folder to start fresh.

---

## ğŸ› ï¸ Troubleshooting

- âŒ `ModuleNotFoundError` â†’ Run `pip install chromadb sentence-transformers`
- âŒ `OSError: Unable to load weights` â†’ Check internet â€” first run downloads model.
- âŒ `ValueError: Expected EmbeddingFunction.__call__...` â†’ Ensure your `__call__` method uses `input: List[str]`, not `texts`.
- âŒ `AttributeError: 'Client' object has no attribute 'persist'` â†’ Youâ€™re on Chroma 1.0+ â€” persistence is automatic. Delete the `.persist()` call.
- âŒ `sqlite3.OperationalError: database is locked` â†’ Another process is using the DB. Close other scripts or reboot.
- ğŸ¢ *First query is slow?* â†’ Normal! Model loads and indexes on first use.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ README.md                 # You are here!
â”œâ”€â”€ chroma_local_search.py    # The main runnable script
â””â”€â”€ chroma_store/             # Auto-created persistent database (after first run)
```

---

## ğŸ“š Learn More

- [ChromaDB Official Docs](https://docs.trychroma.com/)
- [Sentence-Transformers Documentation](https://www.sbert.net/)
- [BGE Model Card (Hugging Face)](https://huggingface.co/BAAI/bge-small-en-v1.5)

---

## ğŸ™Œ Acknowledgements

Inspired by the ChromaDB community and Hugging Faceâ€™s amazing open-source models. Built to empower beginners and tinkerers.

---

## ğŸ“œ License

MIT â€” Do whatever you want with it. Share, learn, build!

---
